{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "!pip install -q monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'segment-anything'...\n",
      "remote: Enumerating objects: 295, done.\u001b[K\n",
      "remote: Total 295 (delta 0), reused 0 (delta 0), pack-reused 295\u001b[K\n",
      "Receiving objects: 100% (295/295), 18.30 MiB | 38.09 MiB/s, done.\n",
      "Resolving deltas: 100% (155/155), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/facebookresearch/segment-anything.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/jgr7704/neuro/segment-anything\n"
     ]
    }
   ],
   "source": [
    "%cd /scratch/jgr7704/neuro/segment-anything/\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m.\u001b[0m/          \u001b[01;34m.ipynb_checkpoints\u001b[0m/  \u001b[01;34massets\u001b[0m/     \u001b[01;34msegment_anything\u001b[0m/\n",
      "\u001b[01;34m..\u001b[0m/         CODE_OF_CONDUCT.md   \u001b[01;34mdemo\u001b[0m/       \u001b[01;34msegment_anything.egg-info\u001b[0m/\n",
      ".flake8     CONTRIBUTING.md      \u001b[01;32mlinter.sh\u001b[0m*  setup.cfg\n",
      "\u001b[01;34m.git\u001b[0m/       LICENSE              \u001b[01;34mnotebooks\u001b[0m/  setup.py\n",
      ".gitignore  README.md            \u001b[01;34mscripts\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///scratch/jgr7704/neuro/segment-anything\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hInstalling collected packages: segment-anything\n",
      "  Attempting uninstall: segment-anything\n",
      "    Found existing installation: segment-anything 1.0\n",
      "    Uninstalling segment-anything-1.0:\n",
      "      Successfully uninstalled segment-anything-1.0\n",
      "  Running setup.py develop for segment-anything\n",
      "Successfully installed segment-anything-1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "join = os.path.join\n",
    "from tqdm import tqdm\n",
    "from skimage import transform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import monai\n",
    "from segment_anything import sam_model_registry\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import random\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import glob\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# set seeds\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/jgr7704/neuro\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %ls -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [00:04<00:00, 57.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def resize(path):\n",
    "  dirs = os.listdir( path )\n",
    "  for item in tqdm(dirs):\n",
    "    if os.path.isfile(path+item):\n",
    "      im = Image.open(path+item)\n",
    "      f, e = os.path.splitext(path+item)\n",
    "      imResize = im.resize((1024,1024), Image.NEAREST)\n",
    "      imResize.save(f+e, 'PNG', quality=100)\n",
    "\n",
    "label_path =  \"/scratch/jgr7704/neuro/dataset/axon/\"\n",
    "output_features_path = \"/scratch/jgr7704/neuro/dataset/image/\"\n",
    "resize(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>228.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>225.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_ids\n",
       "0  228.png\n",
       "1   27.png\n",
       "2  175.png\n",
       "3  225.png\n",
       "4  172.png"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids=[]\n",
    "label_filenames = [f for f in listdir(label_path) if isfile(join(label_path, f))]\n",
    "feature_filenames = [f for f in listdir(output_features_path) if isfile(join(output_features_path, f))]\n",
    "for i in range(len(feature_filenames)):\n",
    "    \n",
    "    # print(feature_filenames[i])\n",
    "    ids.append(feature_filenames[i])\n",
    "# print(ids)\n",
    "\n",
    "df = pd.DataFrame(ids ,columns=[\"file_ids\"])\n",
    "df.to_csv('/scratch/jgr7704/neuro/full_file_ids.csv', index=False)\n",
    "\n",
    "#sanity check\n",
    "df = pd.read_csv('/scratch/jgr7704/neuro/full_file_ids.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>103.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>105.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>106.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>107.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>108.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>109.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>110.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>111.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_ids\n",
       "0     1.png\n",
       "1    10.png\n",
       "2   100.png\n",
       "3   101.png\n",
       "4   102.png\n",
       "5   103.png\n",
       "6   104.png\n",
       "7   105.png\n",
       "8   106.png\n",
       "9   107.png\n",
       "10  108.png\n",
       "11  109.png\n",
       "12   11.png\n",
       "13  110.png\n",
       "14  111.png"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "df = pd.read_csv('/scratch/jgr7704/neuro/full_file_ids.csv')\n",
    "ids = df['file_ids'].tolist()\n",
    "non_empty_ids = []\n",
    "# print(ids)\n",
    "for file_id in ids:\n",
    "    # print(f\"--------------{label_path}----------\",)\n",
    "    mask_path = os.path.join(label_path, file_id)\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if cv2.countNonZero(mask) > 0:\n",
    "        non_empty_ids.append(file_id)\n",
    "\n",
    "df_non_empty = pd.DataFrame(non_empty_ids, columns=[\"file_ids\"])\n",
    "df_non_empty.sort_values(by='file_ids', inplace=True)  # Sort the DataFrame by 'file_ids'\n",
    "df_non_empty.to_csv('/scratch/jgr7704/neuro/file_ids.csv', index=False)\n",
    "\n",
    "\n",
    "dif = pd.read_csv('/scratch/jgr7704/neuro/file_ids.csv')\n",
    "dif.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # self.img_path = \"/scratch/jgr7704/neuro/images\"\n",
    "        # self.mask_path = \"/scratch/jgr7704/neuro/axon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, csv_file, bbox_shift=20):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.ids = self.df[\"file_ids\"]\n",
    "        self.img_path = \"/scratch/jgr7704/neuro/dataset/image\"\n",
    "        self.mask_path = \"/scratch/jgr7704/neuro/dataset/axon\"\n",
    "        self.bbox_shift = bbox_shift\n",
    "        print(f\"number of images: {len(self.ids)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load image and mask using the ID from the CSV\n",
    "        img_name = f\"{self.ids[index]}\"\n",
    "        mask_name = f\"{self.ids[index]}\"\n",
    "     \n",
    "        # Load and resize image to 1024x1024, then convert to RGB\n",
    "        img = Image.open(join(self.img_path, img_name)).resize((1024, 1024)).convert(\"RGB\")\n",
    "        img = np.array(img)  # Convert image to numpy array\n",
    "\n",
    "        img = img / 255.0\n",
    "\n",
    "        # Load and resize mask to 1024x1024\n",
    "        mask = Image.open(join(self.mask_path, mask_name)).resize((1024, 1024))\n",
    "        mask = np.array(mask)  # Convert mask to numpy array\n",
    "\n",
    "        # Convert the shape to (3, H, W) for image and (1, H, W) for mask\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        mask = np.expand_dims(mask, axis=0)  # Add an extra dimension for the channel\n",
    "\n",
    "        label_ids = np.unique(mask)[1:]\n",
    "        mask_binary = np.uint8(mask == random.choice(label_ids.tolist()))#.reshape((1024, 1024))\n",
    "        mask_binary = mask_binary[0]\n",
    "        # mask_binary = np.uint8(mask == random.choice(label_ids.tolist()))[1]  # only one label, (1024, 1024)\n",
    "\n",
    "        # print(mask_binary.shape)\n",
    "        y_indices, x_indices = np.where(mask_binary > 0)\n",
    "        x_min, x_max = np.min(x_indices), np.max(x_indices)\n",
    "        y_min, y_max = np.min(y_indices), np.max(y_indices)\n",
    "        # add perturbation to bounding box coordinates\n",
    "        H, W = mask_binary.shape\n",
    "        x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n",
    "        x_max = min(W, x_max + random.randint(0, self.bbox_shift))\n",
    "        y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n",
    "        y_max = min(H, y_max + random.randint(0, self.bbox_shift))\n",
    "        bboxes = np.array([x_min, y_min, x_max, y_max])\n",
    "\n",
    "        return (\n",
    "            torch.tensor(img).float(),\n",
    "            torch.tensor(mask_binary[None, :, :]).long(),\n",
    "            torch.tensor(bboxes).float(),\n",
    "            img_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/drive/folders/1ETWmi4AiniJeWOt6HAsYgTjYv_fkgzoN?usp=drive_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/scratch/jgr7704/neuro/checkpoint_save’: File exists\n",
      "/scratch/jgr7704/neuro\n"
     ]
    }
   ],
   "source": [
    "%mkdir /scratch/jgr7704/neuro/checkpoint_save\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/jgr7704/neuro/segment-anything'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.0005\n",
    "batch_size = 1\n",
    "data_path = \"/scratch/jgr7704/neuro/dataset\"\n",
    "checkpoint = \"/scratch/jgr7704/neuro/medsam_vit_b.pth\"\n",
    "model_type = \"vit_b\"\n",
    "work_dir = \"/scratch/jgr7704/neuro/checkpoint_save\"\n",
    "num_epochs = 2\n",
    "num_workers=6\n",
    "use_wandb = 1\n",
    "use_amp = 0\n",
    "resume = \"\"\n",
    "task_name = \"euroSAM-ViT-\"\n",
    "num_epochs = num_epochs\n",
    "iter_num = 0\n",
    "start_epoch = 0\n",
    "losses = []\n",
    "best_loss = 1e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(work_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 242\n",
      "torch.Size([1, 3, 1024, 1024]) torch.Size([1, 1, 1024, 1024]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your dataset\n",
    "tr_dataset = SegmentationDataset(csv_file='file_ids.csv',)\n",
    "tr_dataloader = DataLoader(tr_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([251 / 255, 252 / 255, 30 / 255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(\n",
    "        plt.Rectangle((x0, y0), w, h, edgecolor=\"blue\", facecolor=(0, 0, 0, 0), lw=2)\n",
    "    )\n",
    "\n",
    "for step, (image, mask_binary, bboxes, img_name) in enumerate(tr_dataloader):\n",
    "    print(image.shape, mask_binary.shape, bboxes.shape)\n",
    "    # show the example\n",
    "    _, axs = plt.subplots(1, 2, figsize=(25, 25))\n",
    "    idx = random.randint(0, image.size(0) - 1)  # Update this line to get a valid index\n",
    "    axs[0].imshow(image[idx].cpu().permute(1, 2, 0).numpy())\n",
    "    show_mask(mask_binary[idx].cpu().numpy()[0], axs[0])  # Passing the 2D mask to show_mask\n",
    "    show_box(bboxes[idx].numpy(), axs[0])\n",
    "    axs[0].axis(\"off\")\n",
    "    # set title\n",
    "    axs[0].set_title(img_name[idx])\n",
    "    idx = random.randint(0, image.size(0) - 1)  # Update this line to get a valid index\n",
    "    axs[1].imshow(image[idx].cpu().permute(1, 2, 0).numpy())\n",
    "    show_mask(mask_binary[idx].cpu().numpy()[0], axs[1])  # Passing the 2D mask to show_mask\n",
    "    show_box(bboxes[idx].numpy(), axs[1])\n",
    "    axs[1].axis(\"off\")\n",
    "    # set title\n",
    "    axs[1].set_title(img_name[idx])\n",
    "    # plt.show()\n",
    "    plt.subplots_adjust(wspace=0.01, hspace=0)\n",
    "    plt.savefig(\"./data_sanitycheck.png\", bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuroSAM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        image_encoder,\n",
    "        mask_decoder,\n",
    "        prompt_encoder,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.mask_decoder = mask_decoder\n",
    "        self.prompt_encoder = prompt_encoder\n",
    "        # freeze prompt encoder\n",
    "\n",
    "        for param in self.prompt_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for param in self.image_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, image, box):\n",
    "        image_embedding = self.image_encoder(image)  # (B, 256, 64, 64)\n",
    "        # do not compute gradients for prompt encoder\n",
    "        with torch.no_grad():\n",
    "            box_torch = torch.as_tensor(box, dtype=torch.float32, device=image.device)\n",
    "            if len(box_torch.shape) == 2:\n",
    "                box_torch = box_torch[:, None, :]  # (B, 1, 4)\n",
    "\n",
    "            sparse_embeddings, dense_embeddings = self.prompt_encoder(\n",
    "                points=None,\n",
    "                boxes=box_torch,\n",
    "                masks=None,\n",
    "            )\n",
    "\n",
    "        # print(\"Shape of image_embedding:\", image_embedding.shape)\n",
    "        # print(\"Shape of dense_prompt_embeddings:\", dense_embeddings.shape)\n",
    "    \n",
    "\n",
    "        low_res_masks, iou_predictions = self.mask_decoder(\n",
    "            image_embeddings=image_embedding,  # (B, 256, 64, 64)\n",
    "            image_pe=self.prompt_encoder.get_dense_pe(),  # (1, 256, 64, 64)\n",
    "            sparse_prompt_embeddings=sparse_embeddings,  # (B, 2, 256)\n",
    "            dense_prompt_embeddings=dense_embeddings,  # (B, 256, 64, 64)\n",
    "            multimask_output=False,\n",
    "        )\n",
    "\n",
    "        ori_res_masks = F.interpolate(\n",
    "            low_res_masks,\n",
    "            size=(image.shape[2], image.shape[3]),\n",
    "            mode=\"bilinear\",\n",
    "            align_corners=False,\n",
    "        )\n",
    "        return ori_res_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sam_model_registry[model_type](checkpoint=checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neuroSAM(\n",
       "  (image_encoder): ImageEncoderViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (neck): Sequential(\n",
       "      (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): LayerNorm2d()\n",
       "      (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (3): LayerNorm2d()\n",
       "    )\n",
       "  )\n",
       "  (mask_decoder): MaskDecoder(\n",
       "    (transformer): TwoWayTransformer(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x TwoWayAttentionBlock(\n",
       "          (self_attn): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_token_to_image): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (lin1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "            (lin2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "            (act): ReLU()\n",
       "          )\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn_image_to_token): Attention(\n",
       "            (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "            (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_attn_token_to_image): Attention(\n",
       "        (q_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (k_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (v_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (out_proj): Linear(in_features=128, out_features=256, bias=True)\n",
       "      )\n",
       "      (norm_final_attn): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (iou_token): Embedding(1, 256)\n",
       "    (mask_tokens): Embedding(4, 256)\n",
       "    (output_upscaling): Sequential(\n",
       "      (0): ConvTranspose2d(256, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): GELU(approximate='none')\n",
       "    )\n",
       "    (output_hypernetworks_mlps): ModuleList(\n",
       "      (0-3): 4 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=32, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (iou_prediction_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (prompt_encoder): PromptEncoder(\n",
       "    (pe_layer): PositionEmbeddingRandom()\n",
       "    (point_embeddings): ModuleList(\n",
       "      (0-3): 4 x Embedding(1, 256)\n",
       "    )\n",
       "    (not_a_point_embed): Embedding(1, 256)\n",
       "    (mask_downscaling): Sequential(\n",
       "      (0): Conv2d(1, 4, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (1): LayerNorm2d()\n",
       "      (2): GELU(approximate='none')\n",
       "      (3): Conv2d(4, 16, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (4): LayerNorm2d()\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (no_mask_embed): Embedding(1, 256)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurosam_model = neuroSAM(\n",
    "        image_encoder=model.image_encoder,\n",
    "        mask_decoder=model.mask_decoder,\n",
    "        prompt_encoder=model.prompt_encoder,\n",
    "    ).to(device)\n",
    "\n",
    "neurosam_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total parameters:  93735472\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        \"Number of total parameters: \",\n",
    "        sum(p.numel() for p in neurosam_model.parameters()),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters:  4058340\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "        \"Number of trainable parameters: \",\n",
    "        sum(p.numel() for p in neurosam_model.parameters() if p.requires_grad),\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask_encdec_params = neurosam_model.mask_decoder.parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "        img_mask_encdec_params, lr=0.0001, weight_decay=0.01\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_loss = monai.losses.DiceLoss(sigmoid=True, squared_pred=True, reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  242\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples: \", len(tr_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:346oheor) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.005 MB of 0.005 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dainty-surf-1</strong> at: <a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-/runs/346oheor' target=\"_blank\">https://wandb.ai/jgr7704/a-NeuroSAM-ViT-/runs/346oheor</a><br/> View project at: <a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-' target=\"_blank\">https://wandb.ai/jgr7704/a-NeuroSAM-ViT-</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240513_054805-346oheor/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:346oheor). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f875eb23fd40609a48a95154435c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111202272069123, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/jgr7704/neuro/wandb/run-20240513_054937-ik47b4ge</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-/runs/ik47b4ge' target=\"_blank\">snowy-pyramid-2</a></strong> to <a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-' target=\"_blank\">https://wandb.ai/jgr7704/a-NeuroSAM-ViT-</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/jgr7704/a-NeuroSAM-ViT-/runs/ik47b4ge' target=\"_blank\">https://wandb.ai/jgr7704/a-NeuroSAM-ViT-/runs/ik47b4ge</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if use_wandb:\n",
    "    import wandb\n",
    "\n",
    "    wandb.login()\n",
    "    wandb.init(\n",
    "        project= task_name,\n",
    "        config={\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"data_path\": data_path,\n",
    "            \"model_type\": model_type,\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = datetime.now().strftime(\"%Y%m%d-%H%M\")\n",
    "model_save_path = join(work_dir, task_name + \"-\" + run_id)\n",
    "device = torch.device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resume is not None:\n",
    "    if os.path.isfile(resume):\n",
    "        checkpoint = torch.load(resume, map_location=device)\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "if use_amp:\n",
    "    scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GO Ahead\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(\"GO Ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 403.7 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime! e/acc\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "  print('Not using a high-RAM runtime')\n",
    "else:\n",
    "  print('You are using a high-RAM runtime! e/acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:39<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0551, Epoch: 0, Loss: 0.6663818996229607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0553, Epoch: 1, Loss: 0.5133766145812525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0554, Epoch: 2, Loss: 0.46390441026059426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0556, Epoch: 3, Loss: 0.42565348852595847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0557, Epoch: 4, Loss: 0.40664316735450656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0559, Epoch: 5, Loss: 0.3883818594190095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0601, Epoch: 6, Loss: 0.3733848924149616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0602, Epoch: 7, Loss: 0.35342097783237075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0604, Epoch: 8, Loss: 0.35409382177339055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0605, Epoch: 9, Loss: 0.3383667509832817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0607, Epoch: 10, Loss: 0.3305539314430284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0609, Epoch: 11, Loss: 0.3168256492721095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0610, Epoch: 12, Loss: 0.31209921363849363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:42<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0612, Epoch: 13, Loss: 0.31389782636492086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0614, Epoch: 14, Loss: 0.304780963174535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0615, Epoch: 15, Loss: 0.3011044426454053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0617, Epoch: 16, Loss: 0.2942063955752434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0618, Epoch: 17, Loss: 0.28687485526953493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0620, Epoch: 18, Loss: 0.28229292737188677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0622, Epoch: 19, Loss: 0.27987140899377244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0623, Epoch: 20, Loss: 0.2766515840911519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0625, Epoch: 21, Loss: 0.27130878616232595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:39<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0626, Epoch: 22, Loss: 0.27130032191632697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0628, Epoch: 23, Loss: 0.26276449177460554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0630, Epoch: 24, Loss: 0.2655976826781059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0631, Epoch: 25, Loss: 0.259635554247872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0633, Epoch: 26, Loss: 0.25423079398286785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0634, Epoch: 27, Loss: 0.25163693285520145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0636, Epoch: 28, Loss: 0.2526098791958138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0638, Epoch: 29, Loss: 0.24459256459012071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:39<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0639, Epoch: 30, Loss: 0.2433810052365312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:37<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0641, Epoch: 31, Loss: 0.23750506352277712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0642, Epoch: 32, Loss: 0.2398912401491181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0644, Epoch: 33, Loss: 0.24658153237025274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:38<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0646, Epoch: 34, Loss: 0.2336092028782328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0647, Epoch: 35, Loss: 0.22828979603173327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:32<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0649, Epoch: 36, Loss: 0.22635866679962247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0651, Epoch: 37, Loss: 0.22591224277229724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0652, Epoch: 38, Loss: 0.23216448085869495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0654, Epoch: 39, Loss: 0.22420081965377964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:32<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0655, Epoch: 40, Loss: 0.21871658970304297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0657, Epoch: 41, Loss: 0.2160882432693886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0658, Epoch: 42, Loss: 0.21254626621349224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0700, Epoch: 43, Loss: 0.2133166082589829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:31<00:00,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0702, Epoch: 44, Loss: 0.2157146693419866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0703, Epoch: 45, Loss: 0.21110026942589225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0705, Epoch: 46, Loss: 0.20479842505699866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0706, Epoch: 47, Loss: 0.2044306961796343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0708, Epoch: 48, Loss: 0.20493585492689084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0710, Epoch: 49, Loss: 0.20469725523066717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0711, Epoch: 50, Loss: 0.19950921083819817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0713, Epoch: 51, Loss: 0.19943689576570423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0714, Epoch: 52, Loss: 0.19455441507932061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0716, Epoch: 53, Loss: 0.19615770063335966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:32<00:00,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0718, Epoch: 54, Loss: 0.19573521813478212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0719, Epoch: 55, Loss: 0.1924587043844689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0721, Epoch: 56, Loss: 0.191245457482103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:32<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0722, Epoch: 57, Loss: 0.19160829662225554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:32<00:00,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0724, Epoch: 58, Loss: 0.1924722042723068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:31<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0725, Epoch: 59, Loss: 0.19219629995184814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0727, Epoch: 60, Loss: 0.1872814404101911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0729, Epoch: 61, Loss: 0.18429720761153956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:37<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0730, Epoch: 62, Loss: 0.18263702251449906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0732, Epoch: 63, Loss: 0.17949763717153014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0733, Epoch: 64, Loss: 0.18077645316349025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0735, Epoch: 65, Loss: 0.17638320118745332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0737, Epoch: 66, Loss: 0.17525732327113508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0738, Epoch: 67, Loss: 0.17976773613716063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0740, Epoch: 68, Loss: 0.17948350072278027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0741, Epoch: 69, Loss: 0.17663231566239196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0743, Epoch: 70, Loss: 0.17411587455336977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0745, Epoch: 71, Loss: 0.17358312524731476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0746, Epoch: 72, Loss: 0.17402202530118688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0748, Epoch: 73, Loss: 0.1715024756383599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0749, Epoch: 74, Loss: 0.17264428629667433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:33<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0751, Epoch: 75, Loss: 0.16941353372642112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0753, Epoch: 76, Loss: 0.16876498216384428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:37<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0754, Epoch: 77, Loss: 0.16853169783084224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0756, Epoch: 78, Loss: 0.16629529524115358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0757, Epoch: 79, Loss: 0.16546604242098528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0759, Epoch: 80, Loss: 0.16794990520166905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0801, Epoch: 81, Loss: 0.16392068261922146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0802, Epoch: 82, Loss: 0.16441652959374967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:34<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0804, Epoch: 83, Loss: 0.16142663562909942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0805, Epoch: 84, Loss: 0.16056833202135265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0807, Epoch: 85, Loss: 0.15987419841726044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:38<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0809, Epoch: 86, Loss: 0.15860841335937442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:39<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0810, Epoch: 87, Loss: 0.15943843411490383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0812, Epoch: 88, Loss: 0.16021880536838687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:36<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0814, Epoch: 89, Loss: 0.16018022861161668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:35<00:00,  2.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0815, Epoch: 90, Loss: 0.15882002372155546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:37<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0817, Epoch: 91, Loss: 0.15613495820507223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:38<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0819, Epoch: 92, Loss: 0.15558212122172735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:38<00:00,  2.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0820, Epoch: 93, Loss: 0.15404502790869518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 242/242 [01:39<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 20240513-0822, Epoch: 94, Loss: 0.1517198226217536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 236/242 [01:36<00:02,  2.46it/s]"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    epoch_loss = 0\n",
    "    for step, (image, gt2D, boxes, _) in enumerate(tqdm(tr_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        boxes_np = boxes.detach().cpu().numpy()\n",
    "        image, gt2D = image.to(device), gt2D.to(device)\n",
    "        if use_amp:\n",
    "            ## AMP\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
    "                neurosam_pred = neurosam_model(image, boxes_np)\n",
    "                loss = seg_loss(neurosam_pred, gt2D) + ce_loss(\n",
    "                    neurosam_pred, gt2D.float()\n",
    "                )\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        else:\n",
    "            neurosam_pred = neurosam_model(image,boxes_np)\n",
    "            loss = seg_loss(neurosam_pred, gt2D) + ce_loss(neurosam_pred, gt2D.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        iter_num += 1\n",
    "\n",
    "    epoch_loss /= step\n",
    "    losses.append(epoch_loss)\n",
    "    if use_wandb:\n",
    "        wandb.log({\"epoch_loss\": epoch_loss})\n",
    "    print(\n",
    "        f'Time: {datetime.now().strftime(\"%Y%m%d-%H%M\")}, Epoch: {epoch}, Loss: {epoch_loss}'\n",
    "    )\n",
    "    ## save the latest model\n",
    "    checkpoint = {\n",
    "        \"model\": neurosam_model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    }\n",
    "    torch.save(checkpoint, join(model_save_path, \"neurosam_model_latest.pth\"))\n",
    "    ## save the best model\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        checkpoint = {\n",
    "            \"model\": neurosam_model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        torch.save(checkpoint, join(model_save_path, \"neurosam_model_best.pth\"))\n",
    "\n",
    "    # %% plot loss\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Dice + Cross Entropy Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(join(model_save_path, task_name + \"train_loss.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
